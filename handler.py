"""
RunPod Serverless Handler for Hunyuan3D-2.1 (Image-to-3D)

Version: 1.2.0 - Extended numpy compatibility fixes

Generates high-fidelity 3D models with PBR materials from input images.

API:
  Input:
    - image_base64: Base64 encoded input image (required)
    - generate_texture: Whether to generate PBR textures (default: true)
    - output_format: 'glb' or 'obj' (default: 'glb')
    - num_views: Number of views for texture (default: 6)
    - texture_resolution: Texture resolution (default: 512)

  Output:
    - model: Base64 encoded 3D model
    - format: Output format used
"""

import os
import sys
import base64
import tempfile
import traceback
from pathlib import Path

# Add Hunyuan3D paths
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/hy3dshape')
sys.path.insert(0, '/app/hy3dpaint')

import runpod
import torch
import numpy as np

# =============================================================================
# FIX: Monkey-patch torch functions to handle numpy compatibility issues
#
# Two separate issues can occur with certain PyTorch/NumPy version combinations:
# 1. "expected np.ndarray (got numpy.ndarray)" - in torch.from_numpy()
# 2. "Could not infer dtype of numpy.int64" - in torch.tensor() with numpy scalars
#
# These patches handle both cases by converting numpy types to Python natives.
# =============================================================================

def _convert_numpy_scalars(data):
    """Convert numpy scalar types to Python native types."""
    if isinstance(data, (np.integer, np.floating)):
        return data.item()
    elif isinstance(data, np.ndarray):
        return data
    elif isinstance(data, (list, tuple)):
        return type(data)(_convert_numpy_scalars(x) for x in data)
    return data

_original_from_numpy = torch.from_numpy
_original_tensor = torch.tensor

def _patched_from_numpy(ndarray):
    """Wrapper for torch.from_numpy that handles type mismatch errors."""
    try:
        return _original_from_numpy(ndarray)
    except TypeError as e:
        error_msg = str(e)
        if "expected np.ndarray" in error_msg or "Could not infer dtype" in error_msg:
            # Fallback: convert to contiguous array and use torch.tensor()
            if hasattr(ndarray, 'copy'):
                ndarray = np.ascontiguousarray(ndarray)
            return _original_tensor(ndarray)
        raise

def _patched_tensor(data, *args, **kwargs):
    """Wrapper for torch.tensor that handles numpy scalar type errors."""
    try:
        return _original_tensor(data, *args, **kwargs)
    except (TypeError, RuntimeError) as e:
        error_msg = str(e)
        if "Could not infer dtype" in error_msg:
            # Convert numpy scalars to Python native types
            converted_data = _convert_numpy_scalars(data)
            return _original_tensor(converted_data, *args, **kwargs)
        raise

torch.from_numpy = _patched_from_numpy
torch.tensor = _patched_tensor
print("Applied torch.from_numpy and torch.tensor monkey-patches for numpy compatibility")
# =============================================================================


# Global pipelines (loaded once on cold start)
shape_pipeline = None
paint_pipeline = None


def get_device():
    """Get the best available device."""
    if torch.cuda.is_available():
        return torch.device("cuda")
    return torch.device("cpu")


def load_pipelines():
    """Load the shape and paint pipelines."""
    global shape_pipeline, paint_pipeline

    device = get_device()
    print(f"Using device: {device}")

    if shape_pipeline is None:
        print("Loading shape pipeline...")
        try:
            from hy3dshape.pipelines import Hunyuan3DDiTFlowMatchingPipeline
            shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(
                '/models/Hunyuan3D-2.1',
                device=device
            )
            print("Shape pipeline loaded successfully.")
        except Exception as e:
            print(f"Error loading shape pipeline: {e}")
            traceback.print_exc()
            raise

    if paint_pipeline is None:
        print("Loading paint pipeline...")
        try:
            from hy3dpaint.textureGenPipeline import Hunyuan3DPaintPipeline, Hunyuan3DPaintConfig
            config = Hunyuan3DPaintConfig(
                max_num_view=int(os.environ.get('MAX_NUM_VIEW', 6)),
                resolution=int(os.environ.get('TEXTURE_RESOLUTION', 512))
            )
            paint_pipeline = Hunyuan3DPaintPipeline(config)
            print("Paint pipeline loaded successfully.")
        except Exception as e:
            print(f"Error loading paint pipeline: {e}")
            traceback.print_exc()
            raise

    return shape_pipeline, paint_pipeline


def save_base64_to_file(b64_data: str, output_path: str) -> str:
    """Decode base64 data and save to file."""
    # Handle data URI format
    if b64_data.startswith("data:"):
        b64_data = b64_data.split(",", 1)[1]

    decoded = base64.b64decode(b64_data)
    with open(output_path, "wb") as f:
        f.write(decoded)
    return output_path


def encode_file_to_base64(file_path: str) -> str:
    """Read file and encode to base64."""
    with open(file_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def handler(job: dict) -> dict:
    """
    RunPod serverless handler for Hunyuan3D-2.1.
    """
    job_input = job.get("input")

    # Health check - returns immediately without loading model
    if job_input == "health_check" or (isinstance(job_input, dict) and job_input.get("health_check")):
        return {
            "status": "healthy",
            "model_dir": "/models/Hunyuan3D-2.1",
            "model_available": os.path.exists("/models/Hunyuan3D-2.1"),
            "message": "Handler ready."
        }

    if not isinstance(job_input, dict):
        return {"error": "Invalid request: missing 'input' field"}

    # Validate required inputs
    if "image_base64" not in job_input:
        return {"error": "Missing required field: image_base64"}

    # Extract parameters
    image_b64 = job_input["image_base64"]
    generate_texture = job_input.get("generate_texture", True)
    output_format = job_input.get("output_format", "glb").lower()
    num_views = job_input.get("num_views", int(os.environ.get('MAX_NUM_VIEW', 6)))
    texture_resolution = job_input.get("texture_resolution", int(os.environ.get('TEXTURE_RESOLUTION', 512)))

    if output_format not in ["glb", "obj"]:
        return {"error": f"Invalid output_format: {output_format}. Use 'glb' or 'obj'."}

    # Load pipelines
    try:
        shape_pipe, paint_pipe = load_pipelines()
    except Exception as e:
        return {"error": f"Failed to load pipelines: {str(e)}"}

    # Create temp directory
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)

        # Save input image
        image_ext = ".png"
        if "image/jpeg" in image_b64[:50] or "image/jpg" in image_b64[:50]:
            image_ext = ".jpg"
        image_path = temp_path / f"input{image_ext}"

        try:
            save_base64_to_file(image_b64, str(image_path))
            print(f"Input image saved: {image_path}")
        except Exception as e:
            return {"error": f"Failed to decode input image: {str(e)}"}

        # Generate shape (untextured mesh)
        try:
            runpod.serverless.progress_update(job, "Generating 3D shape...")
            print("Generating 3D shape from image...")
            mesh = shape_pipe(image=str(image_path))[0]
            print("Shape generation complete.")
        except Exception as e:
            traceback.print_exc()
            return {"error": f"Shape generation failed: {str(e)}"}

        # Generate texture if requested
        if generate_texture:
            try:
                runpod.serverless.progress_update(job, f"Generating textures ({num_views} views)...")
                print(f"Generating textures ({num_views} views, {texture_resolution}px)...")
                # Update paint pipeline config
                paint_pipe.config.max_num_view = num_views
                paint_pipe.config.resolution = texture_resolution
                mesh = paint_pipe(mesh, image_path=str(image_path))
                print("Texture generation complete.")
            except Exception as e:
                traceback.print_exc()
                return {"error": f"Texture generation failed: {str(e)}"}

        runpod.serverless.progress_update(job, "Exporting mesh...")
        # Export mesh
        output_path = temp_path / f"output.{output_format}"
        try:
            if output_format == "glb":
                mesh.export(str(output_path))
            else:
                mesh.export(str(output_path), file_type='obj')
            print(f"Exported to {output_format.upper()}: {output_path}")
        except Exception as e:
            traceback.print_exc()
            return {"error": f"Failed to export mesh: {str(e)}"}

        # Encode output
        try:
            model_b64 = encode_file_to_base64(str(output_path))
            file_size_mb = os.path.getsize(str(output_path)) / (1024 * 1024)
            print(f"Output encoded: {file_size_mb:.2f} MB")
        except Exception as e:
            return {"error": f"Failed to encode output: {str(e)}"}

        return {
            "model": model_b64,
            "format": output_format,
            "textured": generate_texture
        }


# Entry point
if __name__ == "__main__":
    # Local testing: python handler.py <image.png>
    if len(sys.argv) > 1:
        with open(sys.argv[1], "rb") as f:
            test_image = base64.b64encode(f.read()).decode("utf-8")

        test_job = {
            "input": {
                "image_base64": test_image,
                "generate_texture": True,
                "output_format": "glb"
            }
        }
        result = handler(test_job)
        if "error" in result:
            print(f"Error: {result['error']}")
        else:
            print(f"Success! Format: {result['format']}, Textured: {result['textured']}")
            with open("test_output.glb", "wb") as f:
                f.write(base64.b64decode(result['model']))
            print("Saved to test_output.glb")
    else:
        # Production: RunPod serverless mode
        runpod.serverless.start({"handler": handler})
